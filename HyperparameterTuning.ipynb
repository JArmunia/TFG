{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy \n",
    "import util\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA = \"E:Corrected_FA/ALL_DATA/\"\n",
    "info_data = \"idaSearch_8_01_2020.csv\"\n",
    "\n",
    "# Obtenemos los diccionarios con los nombres de los ficheros que contienen las imágenes\n",
    "AD_CN, groups = util.obtain_data_files(ALL_DATA, info_data)\n",
    "\n",
    "# Cargamos las imágenes\n",
    "CN_imgs = np.array(util.load_data(ALL_DATA, AD_CN[\"CN\"]), dtype='float32')\n",
    "\n",
    "AD_imgs = util.load_data(ALL_DATA, AD_CN[\"AD\"])\n",
    "\n",
    "# Extendemos la clase con menos ejemplos\n",
    "AD_imgs = np.array(util.extend_class(AD_imgs, len(CN_imgs)), dtype='float32')\n",
    "\n",
    "# Creamos las etiquetas 1: AD, 0:CN\n",
    "CN_labels = np.zeros((len(CN_imgs),1), dtype = \"int32\")\n",
    "AD_labels = np.ones((len(AD_imgs),1), dtype = \"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_logdir = os.path.join( os.curdir, \"my_logs\") \n",
    "\n",
    "def get_run_logdir(): \n",
    "    import time \n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") \n",
    "    return os.path.join(root_logdir, run_id) \n",
    "\n",
    "run_logdir = get_run_logdir() # e.g., './ my_logs/ run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(filters, neurons, dropout_rate, regularization):\n",
    "    layers = tf.keras.layers\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv3D(filters, 11, strides = (4,4,4), padding= 'valid', input_shape=(91,109,91, 1), activation = 'relu'),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Conv3D(filters, 5, strides = (1,1,1), padding= 'valid', activation = 'relu'),\n",
    "        layers.BatchNormalization(),    \n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Conv3D(filters, 3, strides = (1,1,1), padding= 'valid', activation = 'relu'),\n",
    "        layers.BatchNormalization(),    \n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Conv3D(filters, 3, strides = (1,1,1), padding= 'valid', activation = 'relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling3D(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        layers.Conv3D(filters, 3, strides = (1,1,1), padding= 'valid', activation = 'relu'),    \n",
    "        layers.GlobalAveragePooling3D(),\n",
    "\n",
    "        layers.Dense(neurons, activation = \"relu\", activity_regularizer= keras.regularizers.l2(regularization)),\n",
    "        layers.Dense(neurons, activation = \"relu\", activity_regularizer= keras.regularizers.l2(regularization)),\n",
    "        layers.Dense(neurons, activation = \"relu\", activity_regularizer= keras.regularizers.l2(regularization)),\n",
    "        layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_def(dropout, regularization):\n",
    "    layers = tf.keras.layers\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv3D(64, 11, strides = (4,4,4), padding= 'valid', input_shape=(91,109,91, 1)),\n",
    "        layers.BatchNormalization(),    \n",
    "        layers.ReLU(),       \n",
    "\n",
    "        layers.Conv3D(128, 5, strides = (1,1,1), padding= 'valid'),\n",
    "        layers.BatchNormalization(),    \n",
    "        layers.ReLU(),\n",
    "\n",
    "        layers.Conv3D(256, 3, strides = (1,1,1), padding= 'valid'),\n",
    "        layers.BatchNormalization(),    \n",
    "        layers.ReLU(),\n",
    "\n",
    "        layers.Conv3D(512, 3, strides = (1,1,1), padding= 'valid'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling3D(),\n",
    "\n",
    "        layers.Conv3D(512, 3, strides = (1,1,1), padding= 'valid'),    \n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.GlobalAveragePooling3D(),\n",
    "\n",
    "        layers.Dense(512, activation = \"relu\"),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        layers.Dense(512, activation = \"relu\"),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        layers.Dense(512, activation = \"relu\"),\n",
    "        layers.Dropout(dropout),\n",
    "\n",
    "        layers.Dense(1, activation = 'sigmoid')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(train_ds, val_ds, train_size, filters, neurons, batch_size = 32, dropout=0.05, reg=0.003, learning_rate = 3e-7, fold = 0, n_epoch = 200):\n",
    "    \"\"\" Crea, compila y entrena un modelo con los parámetros obtenidos, además guarda el modelo con mejor loss y el modelo con mejor accuracy.\n",
    "    Devuelve la evaluación del modelo con mejor loss y la del modelo con mejor accuracy, los path de los modelos y el history del entrenamiento\"\"\"\n",
    "    \n",
    "    loss_path = \"model_loss_{}_{}_{}_{}_{}.h5\".format(filters,neurons, dropout, reg, fold)\n",
    "    \n",
    "    checkpoint_cb_loss = keras.callbacks.ModelCheckpoint(loss_path, monitor=\"val_loss\", save_best_only = True) \n",
    "    \n",
    "    root_logdir = os.path.join(os.curdir, \"my_logs_cv\") \n",
    "    def get_run_logdir(): \n",
    "        run_id = \"run_{}_{}_{}_{}_{}\".format(filters,neurons, dropout, reg, fold) \n",
    "        return os.path.join(root_logdir, run_id) \n",
    "    \n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(get_run_logdir())\n",
    "\n",
    "    # Se crea el modelo\n",
    "    m = create_model_def(dropout, reg)\n",
    "    # Se compila\n",
    "    m.compile(optimizer = keras.optimizers.Adam(learning_rate), loss = tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])       \n",
    "    # Se entrena\n",
    "    history = m.fit(train_ds.repeat(), epochs = n_epoch, steps_per_epoch= train_size/batch_size, \n",
    "                    validation_data = val_ds, verbose = 0, callbacks =[checkpoint_cb_loss, \n",
    "                                                                       tensorboard_cb]) \n",
    "    # Evaluacion del modelo con mejor loss\n",
    "    m = keras.models.load_model(loss_path) \n",
    "    evaluation_loss = m.evaluate(val_ds)\n",
    "    \n",
    "    \n",
    "    return {\"ev_loss\": evaluation_loss, \"loss_path\": loss_path, \"history\": history}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data = util.train_test_split(CN_imgs, CN_labels, AD_imgs, AD_labels, 0.15)\n",
    "\n",
    "CN_imgs, AD_imgs = None, None # Liberamos memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((91, 109, 91, 1), (1,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_data = util.k_fold(data[\"train_imgs\"], data[\"train_labels\"], 5, 0 )\n",
    "train_ds = fold_data[\"train_ds\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_ds': <ShuffleDataset shapes: ((91, 109, 91, 1), (1,)), types: (tf.float32, tf.int32)>,\n",
       " 'val_ds': <ShuffleDataset shapes: ((91, 109, 91, 1), (1,)), types: (tf.float32, tf.int32)>,\n",
       " 'train_size': 300,\n",
       " 'val_size': 74}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 376ms/step - loss: 0.6708 - accuracy: 0.7833\n",
      "4718.74587726593\n"
     ]
    }
   ],
   "source": [
    "fold_data = util.k_fold(data[\"train_imgs\"], data[\"train_labels\"], 5, 1 )\n",
    "train_ds = fold_data[\"train_ds\"].map(lambda tensor, labels : util.transform(tensor,labels), num_parallel_calls=16)\\\n",
    "                                .batch(batch_size).prefetch(8)\n",
    "val_ds = fold_data[\"val_ds\"].batch(fold_data[\"val_size\"])\n",
    "train_size = fold_data[\"train_size\"]\n",
    "start = time.time()\n",
    "evaluations = try_model(train_ds, val_ds, train_size, 0, 0,dropout = 0.1, fold= 0, learning_rate = 3e-6, n_epoch = 400)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Javie\\\\OneDrive - unizar.es\\\\Documentos\\\\Universidad\\\\TFG'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model_loss_0_0_0.1_0.003_0.h5\")  # roll back to best model\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-6), loss=tf.keras.losses.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9189684 ],\n",
       "       [0.4244495 ],\n",
       "       [0.79911834],\n",
       "       [0.20836599],\n",
       "       [0.4181527 ],\n",
       "       [0.65679014],\n",
       "       [0.20506841],\n",
       "       [0.8831246 ],\n",
       "       [0.22305681],\n",
       "       [0.6291448 ],\n",
       "       [0.9487446 ],\n",
       "       [0.84349126],\n",
       "       [0.14489901],\n",
       "       [0.22651221],\n",
       "       [0.03659551],\n",
       "       [0.7882234 ],\n",
       "       [0.13126223],\n",
       "       [0.12724917],\n",
       "       [0.38470346],\n",
       "       [0.1113186 ],\n",
       "       [0.05739108],\n",
       "       [0.18246384],\n",
       "       [0.8205814 ],\n",
       "       [0.918437  ],\n",
       "       [0.21611376],\n",
       "       [0.0549912 ],\n",
       "       [0.81238294],\n",
       "       [0.24963723],\n",
       "       [0.16593477],\n",
       "       [0.4327924 ],\n",
       "       [0.3404741 ],\n",
       "       [0.10454987],\n",
       "       [0.19310784],\n",
       "       [0.26219666],\n",
       "       [0.74144584],\n",
       "       [0.66255224],\n",
       "       [0.29982603],\n",
       "       [0.20242548],\n",
       "       [0.3364907 ],\n",
       "       [0.54433656],\n",
       "       [0.6760556 ],\n",
       "       [0.11919296],\n",
       "       [0.77755314],\n",
       "       [0.21625437],\n",
       "       [0.35384864],\n",
       "       [0.11689481],\n",
       "       [0.80708706],\n",
       "       [0.96063054],\n",
       "       [0.269359  ],\n",
       "       [0.11514153],\n",
       "       [0.7328346 ],\n",
       "       [0.47494328],\n",
       "       [0.8697426 ],\n",
       "       [0.20230003],\n",
       "       [0.24963723],\n",
       "       [0.04895909],\n",
       "       [0.62782025],\n",
       "       [0.38504958],\n",
       "       [0.03318023],\n",
       "       [0.29828838],\n",
       "       [0.10157411],\n",
       "       [0.95558405],\n",
       "       [0.17420235],\n",
       "       [0.26219666],\n",
       "       [0.14172852],\n",
       "       [0.81269264],\n",
       "       [0.14916837],\n",
       "       [0.19536203],\n",
       "       [0.5341452 ],\n",
       "       [0.27922827],\n",
       "       [0.0784668 ],\n",
       "       [0.21339025],\n",
       "       [0.6297813 ],\n",
       "       [0.03131892],\n",
       "       [0.71426296],\n",
       "       [0.269359  ],\n",
       "       [0.6449528 ],\n",
       "       [0.17434381],\n",
       "       [0.93478703],\n",
       "       [0.2935515 ],\n",
       "       [0.12858833],\n",
       "       [0.87042725],\n",
       "       [0.58907914],\n",
       "       [0.10932333],\n",
       "       [0.8267626 ],\n",
       "       [0.1424412 ],\n",
       "       [0.9154464 ],\n",
       "       [0.06804869],\n",
       "       [0.91375697],\n",
       "       [0.3280652 ],\n",
       "       [0.17672539],\n",
       "       [0.70321435],\n",
       "       [0.02122777],\n",
       "       [0.95492595],\n",
       "       [0.33718008],\n",
       "       [0.48688218],\n",
       "       [0.09349182],\n",
       "       [0.5685935 ],\n",
       "       [0.47319266],\n",
       "       [0.4864774 ],\n",
       "       [0.9441975 ],\n",
       "       [0.08870408],\n",
       "       [0.84479994],\n",
       "       [0.8743696 ],\n",
       "       [0.54376644],\n",
       "       [0.9492601 ],\n",
       "       [0.95051104],\n",
       "       [0.29715705],\n",
       "       [0.2936035 ],\n",
       "       [0.03146427],\n",
       "       [0.11894929],\n",
       "       [0.87648183],\n",
       "       [0.32801327],\n",
       "       [0.75743395],\n",
       "       [0.03276338],\n",
       "       [0.8831246 ],\n",
       "       [0.8656497 ],\n",
       "       [0.51273006],\n",
       "       [0.3184968 ],\n",
       "       [0.14865126],\n",
       "       [0.38453007],\n",
       "       [0.15559366],\n",
       "       [0.47946718],\n",
       "       [0.5374843 ],\n",
       "       [0.80708706],\n",
       "       [0.8000218 ],\n",
       "       [0.16593477],\n",
       "       [0.29715705],\n",
       "       [0.7551983 ],\n",
       "       [0.21625437],\n",
       "       [0.26085076],\n",
       "       [0.39595222],\n",
       "       [0.84349126],\n",
       "       [0.11191923],\n",
       "       [0.04739994],\n",
       "       [0.0313751 ],\n",
       "       [0.20864344],\n",
       "       [0.10136097],\n",
       "       [0.842893  ],\n",
       "       [0.86867845],\n",
       "       [0.2016044 ],\n",
       "       [0.28091198],\n",
       "       [0.6147497 ],\n",
       "       [0.10136097],\n",
       "       [0.92223316],\n",
       "       [0.79783475],\n",
       "       [0.93205565],\n",
       "       [0.5657752 ],\n",
       "       [0.10110103],\n",
       "       [0.2526599 ],\n",
       "       [0.6384657 ],\n",
       "       [0.2936035 ],\n",
       "       [0.52220285],\n",
       "       [0.07473985],\n",
       "       [0.9453022 ],\n",
       "       [0.9713822 ],\n",
       "       [0.49356914],\n",
       "       [0.3953263 ],\n",
       "       [0.2633117 ],\n",
       "       [0.2420644 ],\n",
       "       [0.9006968 ],\n",
       "       [0.8014337 ],\n",
       "       [0.5151496 ],\n",
       "       [0.6611612 ],\n",
       "       [0.2936035 ],\n",
       "       [0.86135334],\n",
       "       [0.29921636],\n",
       "       [0.82922596],\n",
       "       [0.973078  ],\n",
       "       [0.71196437],\n",
       "       [0.26040632],\n",
       "       [0.40708143],\n",
       "       [0.45287338],\n",
       "       [0.76156515],\n",
       "       [0.83916014],\n",
       "       [0.05192721],\n",
       "       [0.63843316],\n",
       "       [0.93107986],\n",
       "       [0.9507928 ],\n",
       "       [0.05721644],\n",
       "       [0.19259213],\n",
       "       [0.8883352 ],\n",
       "       [0.89390075],\n",
       "       [0.8157728 ],\n",
       "       [0.22742677],\n",
       "       [0.22446142],\n",
       "       [0.43373927],\n",
       "       [0.83298457],\n",
       "       [0.9174227 ],\n",
       "       [0.7741878 ],\n",
       "       [0.14629932],\n",
       "       [0.07839874],\n",
       "       [0.34355193],\n",
       "       [0.2915404 ],\n",
       "       [0.3665709 ],\n",
       "       [0.93205565],\n",
       "       [0.6471494 ],\n",
       "       [0.9453022 ],\n",
       "       [0.18099707],\n",
       "       [0.10447396],\n",
       "       [0.8878864 ],\n",
       "       [0.31314722],\n",
       "       [0.80181783],\n",
       "       [0.05726225],\n",
       "       [0.6379459 ],\n",
       "       [0.1205226 ],\n",
       "       [0.12568611],\n",
       "       [0.35063937],\n",
       "       [0.38453007],\n",
       "       [0.81148094],\n",
       "       [0.826334  ],\n",
       "       [0.03429723],\n",
       "       [0.7337877 ],\n",
       "       [0.5374843 ],\n",
       "       [0.918437  ],\n",
       "       [0.5591477 ],\n",
       "       [0.07451639],\n",
       "       [0.21625437],\n",
       "       [0.91997105],\n",
       "       [0.35590178],\n",
       "       [0.13356903],\n",
       "       [0.590402  ],\n",
       "       [0.53774726],\n",
       "       [0.38453007],\n",
       "       [0.32541773],\n",
       "       [0.7943564 ],\n",
       "       [0.17850195],\n",
       "       [0.1445485 ],\n",
       "       [0.48522407],\n",
       "       [0.9699791 ],\n",
       "       [0.29565346],\n",
       "       [0.50410694],\n",
       "       [0.9189684 ],\n",
       "       [0.78895366],\n",
       "       [0.24348956],\n",
       "       [0.16757846],\n",
       "       [0.18721792],\n",
       "       [0.19694604],\n",
       "       [0.7943564 ],\n",
       "       [0.31533623],\n",
       "       [0.6449528 ],\n",
       "       [0.62782025],\n",
       "       [0.18419567],\n",
       "       [0.2995641 ],\n",
       "       [0.8831246 ],\n",
       "       [0.9574808 ],\n",
       "       [0.9055384 ],\n",
       "       [0.30854288],\n",
       "       [0.04711208],\n",
       "       [0.25219932],\n",
       "       [0.37520385],\n",
       "       [0.9713822 ],\n",
       "       [0.49588084],\n",
       "       [0.16059901],\n",
       "       [0.747238  ],\n",
       "       [0.7304564 ],\n",
       "       [0.44364995],\n",
       "       [0.22080795],\n",
       "       [0.34257337],\n",
       "       [0.6259603 ],\n",
       "       [0.20530392],\n",
       "       [0.1102659 ],\n",
       "       [0.41616836],\n",
       "       [0.86135334],\n",
       "       [0.19727615],\n",
       "       [0.7525787 ],\n",
       "       [0.9488754 ],\n",
       "       [0.842893  ],\n",
       "       [0.56093365],\n",
       "       [0.96000695],\n",
       "       [0.7489363 ],\n",
       "       [0.0377581 ],\n",
       "       [0.8743696 ],\n",
       "       [0.06246395],\n",
       "       [0.0761003 ],\n",
       "       [0.01534852],\n",
       "       [0.35063937],\n",
       "       [0.08092364],\n",
       "       [0.7307742 ],\n",
       "       [0.864875  ],\n",
       "       [0.11479436],\n",
       "       [0.29982603],\n",
       "       [0.07698989],\n",
       "       [0.2548186 ],\n",
       "       [0.9487446 ],\n",
       "       [0.9453022 ],\n",
       "       [0.9441975 ],\n",
       "       [0.90619594],\n",
       "       [0.51744527],\n",
       "       [0.7011252 ],\n",
       "       [0.63843316],\n",
       "       [0.7304564 ],\n",
       "       [0.8656497 ],\n",
       "       [0.84362066],\n",
       "       [0.09771445],\n",
       "       [0.54223114],\n",
       "       [0.23982035],\n",
       "       [0.9242917 ],\n",
       "       [0.84289294],\n",
       "       [0.7304565 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 366ms/step - loss: 0.7592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7591670155525208"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_data[\"val_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (preds >= 5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_ds.take(1):  # only take first element of dataset\n",
    "    numpy_images = images.numpy()\n",
    "    numpy_labels = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (model.predict(numpy_images) >= .5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972972972972973"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.mean(preds == numpy_labels)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 27 7 8\n",
      "0.8 0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "tp = np.sum((preds == numpy_labels) & (preds == 1)).astype(\"int32\")\n",
    "tn = np.sum((preds == numpy_labels) & (preds == 0)).astype(\"int32\")\n",
    "fp = np.sum((preds != numpy_labels) & (preds == 1)).astype(\"int32\")\n",
    "fn = np.sum((preds != numpy_labels) & (preds == 0)).astype(\"int32\")\n",
    "print(tp,tn,fp,fn)\n",
    "sensitivity = np.mean(tp /(tp + fn))\n",
    "specificity = np.mean(tn /(tn + fp))\n",
    "print(sensitivity, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 388ms/step - loss: 0.5779 - accuracy: 0.7600\n",
      "0.41 filters, 9999 neurons, 0.2 dropout, 0.003 regularization, 0 fold\n",
      "Loss: 0.5779489696025848, Accuracy: 0.7599999904632568\n",
      "Tiempo de ejecucion de fold: 3272.8806574344635\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.3804 - accuracy: 0.8233\n",
      "0.41 filters, 9999 neurons, 0.2 dropout, 0.003 regularization, 1 fold\n",
      "Loss: 0.3804469764232635, Accuracy: 0.8233333230018616\n",
      "Tiempo de ejecucion de fold: 3223.65621137619\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.4392 - accuracy: 0.8067\n",
      "0.41 filters, 9999 neurons, 0.2 dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.43915838599205015, Accuracy: 0.8066666722297668\n",
      "Tiempo de ejecucion de fold: 3230.420414209366\n",
      "Nuevo mejor modelo de loss con 0.4658514440059662\n",
      "Nuevo mejor modelo de accuracy con 0.796666661898295\n",
      "Definitive evaluation of best loss of model with 0.41 filters, 9999 neurons, None dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.4658514440059662, Accuracy: 0.796666661898295\n",
      "5/5 [==============================] - 2s 387ms/step - loss: 0.8218 - accuracy: 0.7433\n",
      "0.41 filters, 9999 neurons, 0.3 dropout, 0.003 regularization, 0 fold\n",
      "Loss: 0.8217580318450928, Accuracy: 0.7433333396911621\n",
      "Tiempo de ejecucion de fold: 3251.027955532074\n",
      "5/5 [==============================] - 2s 382ms/step - loss: 0.6318 - accuracy: 0.6567\n",
      "0.41 filters, 9999 neurons, 0.3 dropout, 0.003 regularization, 1 fold\n",
      "Loss: 0.6318282961845398, Accuracy: 0.6566666960716248\n",
      "Tiempo de ejecucion de fold: 3243.77707362175\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.5928 - accuracy: 0.7167\n",
      "0.41 filters, 9999 neurons, 0.3 dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.5927723288536072, Accuracy: 0.7166666388511658\n",
      "Tiempo de ejecucion de fold: 3253.247725248337\n",
      "Definitive evaluation of best loss of model with 0.41 filters, 9999 neurons, None dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.6821195522944133, Accuracy: 0.7055555582046509\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 0.5224 - accuracy: 0.7133\n",
      "0.41 filters, 9999 neurons, 0.4 dropout, 0.003 regularization, 0 fold\n",
      "Loss: 0.522357189655304, Accuracy: 0.7133333086967468\n",
      "Tiempo de ejecucion de fold: 3258.0221712589264\n",
      "5/5 [==============================] - 2s 377ms/step - loss: 0.6354 - accuracy: 0.7533\n",
      "0.41 filters, 9999 neurons, 0.4 dropout, 0.003 regularization, 1 fold\n",
      "Loss: 0.6354103922843933, Accuracy: 0.753333330154419\n",
      "Tiempo de ejecucion de fold: 3264.0154671669006\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.5818 - accuracy: 0.7200\n",
      "0.41 filters, 9999 neurons, 0.4 dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.5818204879760742, Accuracy: 0.7200000286102295\n",
      "Tiempo de ejecucion de fold: 3254.7925765514374\n",
      "Definitive evaluation of best loss of model with 0.41 filters, 9999 neurons, None dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.5798626899719238, Accuracy: 0.7288888891537985\n",
      "5/5 [==============================] - 2s 388ms/step - loss: 0.8025 - accuracy: 0.6333\n",
      "0.41 filters, 9999 neurons, 0.5 dropout, 0.003 regularization, 0 fold\n",
      "Loss: 0.8024639368057251, Accuracy: 0.6333333253860474\n",
      "Tiempo de ejecucion de fold: 3270.359650373459\n",
      "5/5 [==============================] - 2s 380ms/step - loss: 0.5848 - accuracy: 0.7433\n",
      "0.41 filters, 9999 neurons, 0.5 dropout, 0.003 regularization, 1 fold\n",
      "Loss: 0.5848392248153687, Accuracy: 0.7433333396911621\n",
      "Tiempo de ejecucion de fold: 3249.0454053878784\n",
      "5/5 [==============================] - 2s 383ms/step - loss: 0.6456 - accuracy: 0.7200\n",
      "0.41 filters, 9999 neurons, 0.5 dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.645590877532959, Accuracy: 0.7200000286102295\n",
      "Tiempo de ejecucion de fold: 3270.102205991745\n",
      "Definitive evaluation of best loss of model with 0.41 filters, 9999 neurons, None dropout, 0.003 regularization, 2 fold\n",
      "Loss: 0.6776313463846843, Accuracy: 0.698888897895813\n",
      "Terminado\n"
     ]
    }
   ],
   "source": [
    "# filters = [160, 192, 256]\n",
    "# neurons = [192, 256, 512]\n",
    "filters = [ 9999]\n",
    "neurons = [ 9999]\n",
    "dropouts = [0.2, .3,.4,.5]\n",
    "n_epoch = 250\n",
    "batch_size = 32\n",
    "n_folds = 5\n",
    "effective_folds = 3\n",
    "histories = []\n",
    "\n",
    "best_model_loss = \"\"\n",
    "best_loss = np.inf\n",
    "best_acc = 0\n",
    "dropout = None\n",
    "reg = 0.003\n",
    "lr = 1e-6\n",
    "f = 0.41\n",
    "\n",
    "best_loss_parameters = []\n",
    "\n",
    "for d in dropouts:\n",
    "    for n in neurons:\n",
    "        run_evaluations = []\n",
    "        for fold in range(effective_folds):\n",
    "            start = time.time()\n",
    "            #print(\"Iniciado modelo con f = {} y n = {}\".format(f,n))\n",
    "            \n",
    "            fold_data = util.k_fold(data[\"train_imgs\"], data[\"train_labels\"], n_folds, fold )\n",
    "            train_ds = fold_data[\"train_ds\"].map(lambda tensor, labels : util.transform(tensor,labels), num_parallel_calls=16)\\\n",
    "                                            .batch(batch_size).prefetch(8)\n",
    "            val_ds = fold_data[\"val_ds\"].batch(fold_data[\"val_size\"])\n",
    "            train_size = fold_data[\"train_size\"]\n",
    "            \n",
    "            evaluations = try_model(train_ds, val_ds, train_size, f, n,dropout = d, fold= fold, learning_rate = lr, n_epoch = n_epoch)\n",
    "            evaluation_loss = evaluations[\"ev_loss\"]\n",
    "            history = evaluations[\"history\"]\n",
    "\n",
    "            print(\"{} filters, {} neurons, {} dropout, {} regularization, {} fold\".format(f,n, d, reg, fold))\n",
    "            print(\"Loss: {}, Accuracy: {}\".format(evaluation_loss[0], evaluation_loss[1]))\n",
    "            \n",
    "            histories.append(history)\n",
    "            run_evaluations.append(evaluation_loss)\n",
    "            end = time.time()\n",
    "            print(\"Tiempo de ejecucion de fold: {}\".format(end-start))\n",
    "            \n",
    "        # Comprobamos si el modelo con mejor loss es el mejor hasta el momento\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for i in range(len(run_evaluations)):\n",
    "            loss += run_evaluations[i][0]\n",
    "            acc += run_evaluations[i][1]\n",
    "        loss /= len(run_evaluations)\n",
    "        acc /= len(run_evaluations)\n",
    "            \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model_loss = evaluations[\"loss_path\"]\n",
    "            print(\"Nuevo mejor modelo de loss con {}\".format(best_loss))\n",
    "\n",
    "        if acc > best_acc:\n",
    "            \n",
    "            best_acc = acc\n",
    "            best_model_acc = evaluations[\"loss_path\"]\n",
    "            print(\"Nuevo mejor modelo de accuracy con {}\".format(best_acc))\n",
    "\n",
    "        print(\"Definitive evaluation of best loss of model with {} filters, {} neurons, {} dropout, {} regularization, {} fold\".format(f,n, dropout, reg, fold))\n",
    "        print(\"Loss: {}, Accuracy: {}\".format(loss, acc))\n",
    "        \n",
    "        \n",
    "print(\"Terminado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "fold = 0\n",
    "fold_data = util.k_fold(data[\"train_imgs\"], data[\"train_labels\"], n_folds, fold )\n",
    "train_ds = fold_data[\"train_ds\"].map(lambda tensor, labels : util.transform(tensor,labels), num_parallel_calls=16)\\\n",
    "                                .batch(batch_size).prefetch(8)\n",
    "val_ds = fold_data[\"val_ds\"].batch(fold_data[\"val_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 2.2075 - accuracy: 0.5469\n"
     ]
    }
   ],
   "source": [
    "m = keras.models.load_model(\"model_loss_0.3_9999_0.1_0.003_1.h5\") \n",
    "evaluation_loss = m.evaluate(data[\"test\"].batch(len(data[\"test_labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: model_loss_0.3_9999_0.1_0.003_0.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f81a993ca2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_loss_0.3_9999_0.1_0.003_0.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mevaluation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tfg\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tfg\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     81\u001b[0m                   (export_dir,\n\u001b[0;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: model_loss_0.3_9999_0.1_0.003_0.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "m = keras.models.load_model(\"model_loss_0.3_9999_0.1_0.003_0.h5\") \n",
    "evaluation_loss = m.evaluate(data[\"test\"].batch(len(data[\"test_labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.models.load_model(\"model_loss_0.3_9999_0.1_0.003_2.h5\") \n",
    "evaluation_loss = m.evaluate(data[\"test\"].batch(len(data[\"test_labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
